# UzLiB Leaderboard

| **Model Name** | **All** | **Correct word** | **Meaning** | **Meaning in context** | **Fill in** |
|:-----------------------------------|-------:|---------------:|----------:|---------------------:|----------:|
| [Gemini 2.0 Pro Exp](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-pro-exp-02-05) | **0.6303** |0.6316 | **0.6229** | **0.7222** | 0.5 |
| [GPT 4o](https://platform.openai.com/playground/chat?models=gpt-4o-2024-11-20) | 0.6287 | **0.6369** | 0.5847 | 0.6667 | **0.5385** |
| [Gemini 2.0 Flash](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-001) | 0.6088 | 0.6123 | 0.5678 | 0.7222 | 0.5385 |
| [Claude 3.7 Sonnet](https://www.anthropic.com/news/claude-3-7-sonnet) | 0.5938 | 0.6189 | 0.6102 | 0.2778 | 0.2308 |
| *Human voters＊* | *0.5894* | *0.6054* | *0.5247* | *0.5254* | *0.5094* |
| [Gemini 2.0 Flash Lite](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-lite-001) | 0.5803 | 0.5943 | 0.4915 | 0.625 | 0.5192 |
| [Llama 3.1 405B](https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct) | 0.5513 | 0.5736 | 0.4534 | 0.4583 | 0.4808 |
| [Gemini 1.5 Pro](https://aistudio.google.com/prompts/new_chat?model=gemini-1.5-pro-002) | 0.5497 | 0.559 | 0.5127 | 0.5833 | 0.4038 |
| [Gemini 1.5 Flash](https://aistudio.google.com/prompts/new_chat?model=gemini-1.5-flash-002) | 0.5465 | 0.5583 | 0.5127 | 0.5417 | 0.3654 |
| [DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3) | 0.5298 | 0.5363 | 0.5297 | 0.4444 | 0.4615 |
| [GPT 4o mini](https://platform.openai.com/playground/chat?models=gpt-4o-mini-2024-07-18) | 0.5261 | 0.5323 | 0.5169 | 0.5139 | 0.4038 |
| [Claude 3.5 Haiku](https://www.anthropic.com/news/3-5-models-and-computer-use) | 0.4686 | 0.4877 | 0.4153 | 0.2778 | 0.4231 |
| [Llama 3.1 70B](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct) | 0.4508 | 0.4724 | 0.3898 | 0.3333 | 0.2692 |
| [Llama 3.3 70B](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct) | 0.4465 | 0.467 | 0.3898 | 0.3611 | 0.2308 |
| [Gemma 2 27B](https://huggingface.co/google/gemma-2-27b-it) | 0.4406 | 0.4564 | 0.3941 | 0.3889 | 0.2692 |
| [Mistral Nemo](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407) | 0.4164 | 0.4364 | 0.3475 | 0.375 | 0.2115 |
| [Mistral 7B Uz](https://huggingface.co/behbudiy/Mistral-7B-Instruct-Uz) | 0.4105 | 0.4337 | 0.3263 | 0.3194 | 0.25 |
| [Qwen2.5 72B](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct) | 0.4025 | 0.4264 | 0.3093 | 0.3194 | 0.25 |
| [Llama 3.1 8B](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) | 0.4009 | 0.4191 | 0.3051 | 0.3611 | 0.3654 |
| [Gemma 2 9B](https://huggingface.co/google/gemma-2-9b-it) | 0.4009 | 0.4171 | 0.339 | 0.3472 | 0.2885 |
| [Mistral Nemo Uz](https://huggingface.co/behbudiy/Mistral-Nemo-Instruct-Uz) | 0.3982 | 0.4177 | 0.2924 | 0.3611 | 0.3654 |
| [Qwen2.5 7B](https://huggingface.co/Qwen/Qwen2.5-7B-Instruct) | 0.3611 | 0.3744 | 0.3178 | 0.2778 | 0.2885 |
| [Phi 4](https://huggingface.co/microsoft/phi-4) | 0.3471 | 0.3564 | 0.2881 | 0.3056 | 0.4038 |
| [Mistral 7B](https://huggingface.co/mistralai/Mistral-7B-v0.3) | 0.3348 | 0.3451 | 0.2797 | 0.3611 | 0.25 |
| [Command R7B](https://huggingface.co/CohereForAI/c4ai-command-r7b-12-2024) | 0.3229 | 0.3271 | 0.3347 | 0.25 | 0.25 |
| [Llama 3.1 8B Uz](https://huggingface.co/behbudiy/Llama-3.1-8B-Instuct-Uz) | 0.3176 | 0.3251 | 0.2881 | 0.2361 | 0.3462 |
| Random Baseline | 0.25 | 0.25 | 0.25 | 0.25 | 0.25 |

＊ Human voters score is not the average of humans doing all the questions but the average of average accurate answers for each question. Also, note that random baseline for humans is 0.4229 due to variable number of options (2-3) in the original questions.